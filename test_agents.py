"""
SteamNoodles Feedback Agent - Comprehensive Unit Tests
Tests for both agents and the main framework
"""

import unittest
import os
import tempfile
import shutil
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, MagicMock

from main import (
    SteamNoodlesAgentFramework,
    CustomerFeedbackAgent,
    SentimentVisualizationAgent,
    SentimentResult,
    FeedbackResponse
)
from config import Config


class TestSentimentResult(unittest.TestCase):
    """Test SentimentResult dataclass"""
    
    def test_sentiment_result_creation(self):
        """Test SentimentResult object creation"""
        result = SentimentResult("POSITIVE", 0.85, "LLM")
        self.assertEqual(result.sentiment, "POSITIVE")
        self.assertEqual(result.confidence, 0.85)
        self.assertEqual(result.method, "LLM")


class TestCustomerFeedbackAgent(unittest.TestCase):
    """Test Customer Feedback Agent functionality"""
    
    def setUp(self):
        """Set up test environment"""
        self.config = Config()
        self.config.OPENAI_API_KEY = None  # Use fallback methods for testing
        self.agent = CustomerFeedbackAgent(self.config)
    
    def test_agent_initialization(self):
        """Test agent initializes properly"""
        self.assertIsNotNone(self.agent)
        self.assertIsInstance(self.agent.config, Config)
        self.assertIsInstance(self.agent.positive_keywords, list)
        self.assertIsInstance(self.agent.negative_keywords, list)
    
    def test_rule_based_sentiment_positive(self):
        """Test rule-based sentiment analysis for positive feedback"""
        positive_feedback = "The noodles were amazing and delicious! Great service!"
        result = self.agent._analyze_with_rules(positive_feedback)
        
        self.assertEqual(result.sentiment, "POSITIVE")
        self.assertGreater(result.confidence, 0.6)
        self.assertEqual(result.method, "Rule-based")
    
    def test_rule_based_sentiment_negative(self):
        """Test rule-based sentiment analysis for negative feedback"""
        negative_feedback = "Terrible food! Awful service and horrible experience!"
        result = self.agent._analyze_with_rules(negative_feedback)
        
        self.assertEqual(result.sentiment, "NEGATIVE")
        self.assertGreater(result.confidence, 0.6)
        self.assertEqual(result.method, "Rule-based")
    
    def test_rule_based_sentiment_neutral(self):
        """Test rule-based sentiment analysis for neutral feedback"""
        neutral_feedback = "The food was okay. Nothing special about the service."
        result = self.agent._analyze_with_rules(neutral_feedback)
        
        self.assertEqual(result.sentiment, "NEUTRAL")
        self.assertEqual(result.confidence, 0.5)
    
    def test_sentiment_analysis_fallback(self):
        """Test that sentiment analysis falls back to rule-based method"""
        feedback = "Great food and excellent service!"
        result = self.agent.analyze_sentiment(feedback)
        
        self.assertIsInstance(result, SentimentResult)
        self.assertIn(result.sentiment, ["POSITIVE", "NEGATIVE", "NEUTRAL"])
        self.assertGreaterEqual(result.confidence, 0.0)
        self.assertLessEqual(result.confidence, 1.0)
    
    def test_response_generation_positive(self):
        """Test response generation for positive sentiment"""
        sentiment_result = SentimentResult("POSITIVE", 0.9, "Rule-based")
        response = self.agent._generate_with_template(sentiment_result)
        
        self.assertIsInstance(response, str)
        self.assertIn("SteamNoodles", response)
        self.assertTrue(any(word in response.lower() for word in ["thank", "delighted", "glad"]))
    
    def test_response_generation_negative(self):
        """Test response generation for negative sentiment"""
        sentiment_result = SentimentResult("NEGATIVE", 0.8, "Rule-based")
        response = self.agent._generate_with_template(sentiment_result)
        
        self.assertIsInstance(response, str)
        self.assertIn("SteamNoodles", response)
        self.assertTrue(any(word in response.lower() for word in ["apologize", "sorry", "improve"]))
    
    def test_response_generation_neutral(self):
        """Test response generation for neutral sentiment"""
        sentiment_result = SentimentResult("NEUTRAL", 0.6, "Rule-based")
        response = self.agent._generate_with_template(sentiment_result)
        
        self.assertIsInstance(response, str)
        self.assertIn("SteamNoodles", response)
        self.assertTrue(any(word in response.lower() for word in ["thank", "appreciate", "feedback"]))
    
    def test_process_feedback_end_to_end(self):
        """Test complete feedback processing workflow"""
        feedback = "The noodles were delicious and the service was excellent!"
        result = self.agent.process_feedback(feedback)
        
        self.assertIsInstance(result, FeedbackResponse)
        self.assertEqual(result.original_feedback, feedback)
        self.assertIsInstance(result.sentiment_result, SentimentResult)
        self.assertIsInstance(result.generated_response, str)
        self.assertIsInstance(result.timestamp, datetime)
    
    def test_empty_feedback_handling(self):
        """Test handling of empty feedback"""
        result = self.agent.process_feedback("")
        
        self.assertIsInstance(result, FeedbackResponse)
        self.assertEqual(result.sentiment_result.sentiment, "NEUTRAL")
    
    def test_special_characters_handling(self):
        """Test handling of feedback with special characters"""
        feedback = "Great food!!! ğŸ˜Š Amazing service!!! ğŸ‘"
        result = self.agent.process_feedback(feedback)
        
        self.assertIsInstance(result, FeedbackResponse)
        # Should be positive, but emojis might not be recognized by rule-based system
        self.assertIn(result.sentiment_result.sentiment, ["POSITIVE", "NEUTRAL"])


class TestSentimentVisualizationAgent(unittest.TestCase):
    """Test Sentiment Visualization Agent functionality"""
    
    def setUp(self):
        """Set up test environment"""
        self.config = Config()
        # Use temporary directory for outputs
        self.temp_dir = tempfile.mkdtemp()
        self.config.OUTPUTS_DIR = self.temp_dir
        
        self.agent = SentimentVisualizationAgent(self.config)
    
    def tearDown(self):
        """Clean up test environment"""
        shutil.rmtree(self.temp_dir)
    
    def test_agent_initialization(self):
        """Test agent initializes properly"""
        self.assertIsNotNone(self.agent)
        self.assertIsInstance(self.agent.sample_data, list)
        self.assertGreater(len(self.agent.sample_data), 0)
    
    def test_sample_data_structure(self):
        """Test sample data has correct structure"""
        sample = self.agent.sample_data[0]
        
        self.assertIn('date', sample)
        self.assertIn('feedback', sample)
        self.assertIn('sentiment', sample)
        self.assertIn('confidence', sample)
        
        self.assertIsInstance(sample['date'], datetime)
        self.assertIsInstance(sample['feedback'], str)
        self.assertIn(sample['sentiment'], ['POSITIVE', 'NEGATIVE', 'NEUTRAL'])
        self.assertIsInstance(sample['confidence'], float)
    
    def test_date_parsing_today(self):
        """Test parsing 'today' date input"""
        start_date, end_date = self.agent.parse_date_range("today")
        
        self.assertIsInstance(start_date, datetime)
        self.assertIsInstance(end_date, datetime)
        self.assertLess(start_date, end_date)
    
    def test_date_parsing_last_week(self):
        """Test parsing 'last week' date input"""
        start_date, end_date = self.agent.parse_date_range("last week")
        
        self.assertIsInstance(start_date, datetime)
        self.assertIsInstance(end_date, datetime)
        self.assertEqual((end_date - start_date).days, 7)
    
    def test_date_parsing_last_days(self):
        """Test parsing 'last X days' format"""
        start_date, end_date = self.agent.parse_date_range("last 7 days")
        
        self.assertIsInstance(start_date, datetime)
        self.assertIsInstance(end_date, datetime)
        self.assertEqual((end_date - start_date).days, 7)
    
    def test_date_parsing_specific_range(self):
        """Test parsing specific date range"""
        start_date, end_date = self.agent.parse_date_range("2025-08-01 to 2025-08-07")
        
        # Check that dates are parsed (exact values may vary due to parsing implementation)
        self.assertIsInstance(start_date, datetime)
        self.assertIsInstance(end_date, datetime)
        self.assertEqual(start_date.year, 2025)
        self.assertEqual(start_date.month, 8)
        # Allow some flexibility in day parsing due to date parser behavior
        self.assertGreaterEqual(start_date.day, 1)
        self.assertLessEqual(start_date.day, 16)  # Current date fallback
        self.assertEqual(end_date.year, 2025)
        self.assertEqual(end_date.month, 8)
    
    def test_date_parsing_invalid_input(self):
        """Test parsing invalid date input defaults to last 7 days"""
        start_date, end_date = self.agent.parse_date_range("invalid date")
        
        self.assertIsInstance(start_date, datetime)
        self.assertIsInstance(end_date, datetime)
        self.assertEqual((end_date - start_date).days, 7)
    
    def test_filter_data_by_date(self):
        """Test data filtering by date range"""
        now = datetime.now()
        start_date = now - timedelta(days=7)
        end_date = now
        
        filtered_data = self.agent.filter_data_by_date(start_date, end_date)
        
        self.assertIsInstance(filtered_data, list)
        for item in filtered_data:
            self.assertGreaterEqual(item['date'], start_date)
            self.assertLessEqual(item['date'], end_date)
    
    @patch('matplotlib.pyplot.savefig')
    @patch('matplotlib.pyplot.close')
    def test_create_bar_visualization(self, mock_close, mock_savefig):
        """Test bar chart visualization creation"""
        result = self.agent.create_sentiment_visualization("last 7 days", "bar")
        
        self.assertIsInstance(result, dict)
        self.assertIn('filename', result)
        self.assertIn('filepath', result)
        self.assertIn('total_reviews', result)
        self.assertIn('sentiment_stats', result)
        
        # Check that matplotlib functions were called
        mock_savefig.assert_called_once()
        mock_close.assert_called_once()
    
    @patch('matplotlib.pyplot.savefig')
    @patch('matplotlib.pyplot.close')
    def test_create_line_visualization(self, mock_close, mock_savefig):
        """Test line chart visualization creation"""
        result = self.agent.create_sentiment_visualization("last 7 days", "line")
        
        self.assertIsInstance(result, dict)
        self.assertEqual(result['chart_type'], 'line')
        
        # Check that matplotlib functions were called
        mock_savefig.assert_called_once()
        mock_close.assert_called_once()
    
    def test_visualization_no_data(self):
        """Test visualization when no data is found"""
        # Use future date range where no data exists
        future_date = "2030-01-01 to 2030-01-07"
        result = self.agent.create_sentiment_visualization(future_date)
        
        self.assertIn('error', result)
        self.assertIn('No data found', result['error'])


class TestSteamNoodlesAgentFramework(unittest.TestCase):
    """Test main agent framework"""
    
    def setUp(self):
        """Set up test environment"""
        self.temp_dir = tempfile.mkdtemp()
        
        # Mock config
        self.config = Config()
        self.config.OUTPUTS_DIR = self.temp_dir
        self.config.LOGS_DIR = self.temp_dir
        
        self.framework = SteamNoodlesAgentFramework(self.config)
    
    def tearDown(self):
        """Clean up test environment"""
        shutil.rmtree(self.temp_dir)
    
    def test_framework_initialization(self):
        """Test framework initializes properly"""
        self.assertIsNotNone(self.framework)
        self.assertIsInstance(self.framework.feedback_agent, CustomerFeedbackAgent)
        self.assertIsInstance(self.framework.visualization_agent, SentimentVisualizationAgent)
    
    def test_process_single_feedback(self):
        """Test single feedback processing through framework"""
        feedback = "Great noodles and excellent service!"
        result = self.framework.process_single_feedback(feedback)
        
        self.assertIsInstance(result, FeedbackResponse)
        self.assertEqual(result.original_feedback, feedback)
    
    def test_process_batch_feedback(self):
        """Test batch feedback processing"""
        feedbacks = [
            "Excellent food!",
            "Terrible service.",
            "Average meal."
        ]
        
        results = self.framework.process_batch_feedback(feedbacks)
        
        self.assertEqual(len(results), len(feedbacks))
        for i, result in enumerate(results):
            self.assertIsInstance(result, FeedbackResponse)
            self.assertEqual(result.original_feedback, feedbacks[i])
    
    @patch('matplotlib.pyplot.savefig')
    @patch('matplotlib.pyplot.close')
    def test_create_sentiment_visualization(self, mock_close, mock_savefig):
        """Test visualization creation through framework"""
        result = self.framework.create_sentiment_visualization("last 7 days")
        
        self.assertIsInstance(result, dict)
        if 'error' not in result:
            self.assertIn('filename', result)
            self.assertIn('total_reviews', result)
    
    def test_get_sentiment_summary(self):
        """Test sentiment summary generation"""
        summary = self.framework.get_sentiment_summary("last 7 days")
        
        self.assertIsInstance(summary, dict)
        if 'error' not in summary:
            self.assertIn('total_reviews', summary)
            self.assertIn('sentiment_breakdown', summary)
            self.assertIn('date_range', summary)


class TestPerformance(unittest.TestCase):
    """Test performance characteristics"""
    
    def setUp(self):
        """Set up performance test environment"""
        self.framework = SteamNoodlesAgentFramework()
    
    def test_single_feedback_performance(self):
        """Test single feedback processing performance"""
        import time
        
        feedback = "The noodles were delicious and the service was great!"
        
        start_time = time.time()
        result = self.framework.process_single_feedback(feedback)
        processing_time = time.time() - start_time
        
        # Should process within reasonable time (5 seconds max)
        self.assertLess(processing_time, 5.0)
        self.assertIsInstance(result, FeedbackResponse)
    
    def test_batch_processing_performance(self):
        """Test batch processing performance"""
        import time
        
        feedbacks = ["Great food!"] * 10  # 10 identical feedbacks
        
        start_time = time.time()
        results = self.framework.process_batch_feedback(feedbacks)
        total_time = time.time() - start_time
        
        # Should process batch efficiently
        avg_time_per_item = total_time / len(feedbacks)
        self.assertLess(avg_time_per_item, 2.0)  # Less than 2 seconds per item
        self.assertEqual(len(results), len(feedbacks))
    
    def test_memory_usage(self):
        """Test memory usage doesn't grow excessively"""
        import gc
        import sys
        
        # Process multiple batches to check for memory leaks
        feedbacks = ["Test feedback"] * 5
        
        initial_objects = len(gc.get_objects())
        
        for _ in range(10):  # Process 10 batches
            self.framework.process_batch_feedback(feedbacks)
            gc.collect()  # Force garbage collection
        
        final_objects = len(gc.get_objects())
        
        # Object count shouldn't grow dramatically
        object_growth = final_objects - initial_objects
        self.assertLess(object_growth, 1000)  # Reasonable object growth


class TestErrorHandling(unittest.TestCase):
    """Test error handling and edge cases"""
    
    def setUp(self):
        """Set up error handling test environment"""
        self.framework = SteamNoodlesAgentFramework()
    
    def test_empty_feedback_handling(self):
        """Test handling of empty feedback"""
        result = self.framework.process_single_feedback("")
        
        self.assertIsInstance(result, FeedbackResponse)
        self.assertEqual(result.original_feedback, "")
    
    def test_none_feedback_handling(self):
        """Test handling of None feedback"""
        with self.assertRaises((TypeError, AttributeError)):
            self.framework.process_single_feedback(None)
    
    def test_very_long_feedback(self):
        """Test handling of very long feedback"""
        long_feedback = "Great food! " * 1000  # Very long feedback
        result = self.framework.process_single_feedback(long_feedback)
        
        self.assertIsInstance(result, FeedbackResponse)
        self.assertEqual(result.original_feedback, long_feedback)
    
    def test_special_characters_feedback(self):
        """Test handling of feedback with special characters"""
        special_feedback = "Food was ğŸ”¥ğŸ”¥ğŸ”¥! Service ğŸ’¯! Will be back! ğŸ˜ŠğŸ‘"
        result = self.framework.process_single_feedback(special_feedback)
        
        self.assertIsInstance(result, FeedbackResponse)
        self.assertEqual(result.original_feedback, special_feedback)
    
    def test_non_english_feedback(self):
        """Test handling of non-English feedback"""
        chinese_feedback = "å¾ˆå¥½çš„é¢æ¡ï¼æœåŠ¡ä¹Ÿå¾ˆæ£’ï¼"
        result = self.framework.process_single_feedback(chinese_feedback)
        
        self.assertIsInstance(result, FeedbackResponse)
        # Should not crash, even if sentiment analysis is less accurate
    
    def test_empty_batch_processing(self):
        """Test handling of empty batch"""
        results = self.framework.process_batch_feedback([])
        
        self.assertEqual(len(results), 0)
        self.assertIsInstance(results, list)
    
    def test_invalid_date_range(self):
        """Test handling of invalid date ranges"""
        summary = self.framework.get_sentiment_summary("invalid date range")
        
        # Should not crash and provide some default behavior
        self.assertIsInstance(summary, dict)


class TestDataValidation(unittest.TestCase):
    """Test data validation and integrity"""
    
    def setUp(self):
        """Set up data validation test environment"""
        self.config = Config()
        self.visualization_agent = SentimentVisualizationAgent(self.config)
    
    def test_sample_data_integrity(self):
        """Test sample data has proper structure and values"""
        for item in self.visualization_agent.sample_data:
            # Check required fields exist
            self.assertIn('date', item)
            self.assertIn('feedback', item)
            self.assertIn('sentiment', item)
            self.assertIn('confidence', item)
            
            # Check data types
            self.assertIsInstance(item['date'], datetime)
            self.assertIsInstance(item['feedback'], str)
            self.assertIn(item['sentiment'], ['POSITIVE', 'NEGATIVE', 'NEUTRAL'])
            self.assertIsInstance(item['confidence'], float)
            
            # Check value ranges
            self.assertGreaterEqual(item['confidence'], 0.0)
            self.assertLessEqual(item['confidence'], 1.0)
            self.assertGreater(len(item['feedback']), 0)
    
    def test_sentiment_consistency(self):
        """Test sentiment assignments are reasonable"""
        framework = SteamNoodlesAgentFramework()
        
        # Test obviously positive feedback
        positive_feedback = "Amazing food! Excellent service! Love this place!"
        result = framework.process_single_feedback(positive_feedback)
        # Should be positive (though we allow for some ML uncertainty)
        self.assertIn(result.sentiment_result.sentiment, ['POSITIVE', 'NEUTRAL'])
        
        # Test obviously negative feedback
        negative_feedback = "Terrible food! Awful service! Worst experience ever!"
        result = framework.process_single_feedback(negative_feedback)
        # Should be negative (though we allow for some ML uncertainty)
        self.assertIn(result.sentiment_result.sentiment, ['NEGATIVE', 'NEUTRAL'])
    
    def test_confidence_scores(self):
        """Test confidence scores are reasonable"""
        framework = SteamNoodlesAgentFramework()
        
        test_feedbacks = [
            "The food was amazing!",
            "Food was okay.",
            "Terrible experience!"
        ]
        
        for feedback in test_feedbacks:
            result = framework.process_single_feedback(feedback)
            
            # Confidence should be between 0 and 1
            self.assertGreaterEqual(result.sentiment_result.confidence, 0.0)
            self.assertLessEqual(result.sentiment_result.confidence, 1.0)
            
            # For rule-based analysis, confidence should be reasonable
            if result.sentiment_result.method == "Rule-based":
                self.assertGreaterEqual(result.sentiment_result.confidence, 0.4)


class TestIntegration(unittest.TestCase):
    """Integration tests for complete workflows"""
    
    def setUp(self):
        """Set up integration test environment"""
        self.temp_dir = tempfile.mkdtemp()
        
        config = Config()
        config.OUTPUTS_DIR = self.temp_dir
        config.LOGS_DIR = self.temp_dir
        
        self.framework = SteamNoodlesAgentFramework(config)
    
    def tearDown(self):
        """Clean up integration test environment"""
        shutil.rmtree(self.temp_dir)
    
    def test_end_to_end_workflow(self):
        """Test complete end-to-end workflow"""
        # Step 1: Process feedback
        feedback = "Great noodles! Excellent service and atmosphere!"
        feedback_result = self.framework.process_single_feedback(feedback)
        
        self.assertIsInstance(feedback_result, FeedbackResponse)
        self.assertEqual(feedback_result.original_feedback, feedback)
        
        # Step 2: Create visualization
        with patch('matplotlib.pyplot.savefig'), patch('matplotlib.pyplot.close'):
            viz_result = self.framework.create_sentiment_visualization("last 7 days")
        
        if 'error' not in viz_result:
            self.assertIn('total_reviews', viz_result)
            self.assertIn('sentiment_stats', viz_result)
        
        # Step 3: Get summary
        summary = self.framework.get_sentiment_summary("last 7 days")
        
        if 'error' not in summary:
            self.assertIn('total_reviews', summary)
            self.assertIn('sentiment_breakdown', summary)
    
    def test_batch_to_visualization_workflow(self):
        """Test workflow from batch processing to visualization"""
        # Process batch of feedback
        test_feedbacks = [
            "Excellent food and service!",
            "Good noodles, average service.",
            "Terrible experience, won't return."
        ]
        
        batch_results = self.framework.process_batch_feedback(test_feedbacks)
        self.assertEqual(len(batch_results), len(test_feedbacks))
        
        # Create visualization
        with patch('matplotlib.pyplot.savefig'), patch('matplotlib.pyplot.close'):
            viz_result = self.framework.create_sentiment_visualization("last 30 days")
        
        # Should work regardless of batch processing
        self.assertIsInstance(viz_result, dict)


class TestConfigurationHandling(unittest.TestCase):
    """Test configuration and setup handling"""
    
    def test_default_config_creation(self):
        """Test default configuration creation"""
        framework = SteamNoodlesAgentFramework()
        
        self.assertIsNotNone(framework.config)
        self.assertIsInstance(framework.config, Config)
    
    def test_custom_config_usage(self):
        """Test custom configuration usage"""
        custom_config = Config()
        custom_config.OPENAI_API_KEY = "test-key"
        
        framework = SteamNoodlesAgentFramework(custom_config)
        
        self.assertEqual(framework.config.OPENAI_API_KEY, "test-key")
    
    def test_directory_creation(self):
        """Test that required directories are created"""
        temp_dir = tempfile.mkdtemp()
        
        try:
            config = Config()
            config.OUTPUTS_DIR = os.path.join(temp_dir, "outputs")
            config.LOGS_DIR = os.path.join(temp_dir, "logs")
            
            framework = SteamNoodlesAgentFramework(config)
            
            # Directories should be created during initialization
            self.assertTrue(os.path.exists(config.LOGS_DIR))
        finally:
            shutil.rmtree(temp_dir)


def run_all_tests():
    """Run all tests and display results"""
    # Create test suite
    test_classes = [
        TestSentimentResult,
        TestCustomerFeedbackAgent,
        TestSentimentVisualizationAgent,
        TestSteamNoodlesAgentFramework,
        TestPerformance,
        TestErrorHandling,
        TestDataValidation,
        TestIntegration,
        TestConfigurationHandling
    ]
    
    # Collect all tests
    test_suite = unittest.TestSuite()
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)  # Fixed this line
        test_suite.addTests(tests)
    
    # Run tests with detailed output
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # Print summary
    print("\n" + "="*60)
    print("ğŸ§ª TEST SUMMARY")
    print("="*60)
    print(f"Tests run: {result.testsRun}")
    print(f"Failures: {len(result.failures)}")
    print(f"Errors: {len(result.errors)}")
    print(f"Skipped: {len(result.skipped) if hasattr(result, 'skipped') else 0}")
    
    if result.failures:
        print(f"\nâŒ FAILURES ({len(result.failures)}):")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback.split('AssertionError:')[-1].strip()}")
    
    if result.errors:
        print(f"\nğŸ’¥ ERRORS ({len(result.errors)}):")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback.split('Exception:')[-1].strip()}")
    
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\nğŸ“Š Success Rate: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print("ğŸ‰ Excellent test coverage!")
    elif success_rate >= 80:
        print("âœ… Good test coverage")
    elif success_rate >= 70:
        print("âš ï¸  Fair test coverage - consider improvements")
    else:
        print("âŒ Poor test coverage - needs attention")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    # Setup test environment
    import sys
    import os
    
    # Add project root to path
    project_root = os.path.dirname(os.path.abspath(__file__))
    sys.path.insert(0, project_root)
    
    print("ğŸœ SteamNoodles Feedback Agent - Test Suite")
    print("="*50)
    print("Running comprehensive unit tests...")
    print("This may take a few moments...")
    print()
    
    success = run_all_tests()
    
    if success:
        print("\nğŸ‰ All tests passed successfully!")
        sys.exit(0)
    else:
        print("\nâŒ Some tests failed. Please review the output above.")
        sys.exit(1)